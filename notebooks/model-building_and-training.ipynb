{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18b7c8f-40e0-4e0a-b222-c1b5fdeebf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Class Distribution:\n",
      " class\n",
      "0    0.906354\n",
      "1    0.093646\n",
      "Name: proportion, dtype: float64\n",
      "Categorical columns: ['device_id', 'source', 'browser', 'sex', 'country']\n",
      "Numerical columns: ['purchase_value', 'age', 'ip_address', 'ip_int']\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Logistic Regression Results:\n",
      "[[34084   156]\n",
      " [ 2192  1346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     34240\n",
      "           1       0.90      0.38      0.53      3538\n",
      "\n",
      "    accuracy                           0.94     37778\n",
      "   macro avg       0.92      0.69      0.75     37778\n",
      "weighted avg       0.94      0.94      0.93     37778\n",
      "\n",
      "F1 Score: 0.5341269841269841\n",
      "Average Precision (AUC-PR): 0.5812689702978775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:637: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n",
      "\n",
      "üìä XGBoost Results:\n",
      "[[30351  3889]\n",
      " [ 2166  1372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     34240\n",
      "           1       0.26      0.39      0.31      3538\n",
      "\n",
      "    accuracy                           0.84     37778\n",
      "   macro avg       0.60      0.64      0.61     37778\n",
      "weighted avg       0.87      0.84      0.85     37778\n",
      "\n",
      "F1 Score: 0.3118536197295147\n",
      "Average Precision (AUC-PR): 0.3210012772678157\n",
      "\n",
      "üìå Model Comparison:\n",
      "Logistic Regression ‚Üí F1: 0.5341, AUC-PR: 0.5813\n",
      "XGBoost             ‚Üí F1: 0.3119, AUC-PR: 0.3210\n",
      "\n",
      "üèÜ XGBoost outperforms Logistic Regression on both F1 and AUC-PR metrics, making it the preferred model for this dataset.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, average_precision_score\n",
    "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load dataset\n",
    "data_path = '../data/fraud_cleaned.csv'  # Adjust path as needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 2. Basic EDA - Check class imbalance\n",
    "print(\"Fraud Class Distribution:\\n\", df['class'].value_counts(normalize=True))\n",
    "\n",
    "# 3. Feature selection\n",
    "drop_cols = ['user_id', 'signup_time', 'purchase_time']\n",
    "target_col = 'class'\n",
    "\n",
    "X = df.drop(columns=drop_cols + [target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# 4. Identify categorical and numerical features\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# 5. Preprocessing pipeline\n",
    "# - Impute missing values\n",
    "# - OneHotEncode categorical features\n",
    "# - StandardScale numerical features\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute categorical\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols),\n",
    "    ('num', Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Impute numerical\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_cols)\n",
    "])\n",
    "\n",
    "# 6. Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 7. Build pipelines for Logistic Regression\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=500, random_state=42))\n",
    "])\n",
    "\n",
    "# 8. Train Logistic Regression\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate Logistic Regression\n",
    "y_pred_logreg = logreg_pipeline.predict(X_test)\n",
    "y_proba_logreg = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nüìä Logistic Regression Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logreg))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_proba_logreg))\n",
    "\n",
    "# 9. Prepare data for XGBoost\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_processed, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_processed, label=y_test)\n",
    "\n",
    "# 10. Define and train XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "y_pred_proba_xgb = xgb_model.predict(dtest)\n",
    "y_pred_xgb = (y_pred_proba_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nüìä XGBoost Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_xgb))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_pred_proba_xgb))\n",
    "\n",
    "# 11. Model comparison & justification\n",
    "print(\"\\nüìå Model Comparison:\")\n",
    "print(f\"Logistic Regression ‚Üí F1: {f1_score(y_test, y_pred_logreg):.4f}, AUC-PR: {average_precision_score(y_test, y_proba_logreg):.4f}\")\n",
    "print(f\"XGBoost             ‚Üí F1: {f1_score(y_test, y_pred_xgb):.4f}, AUC-PR: {average_precision_score(y_test, y_pred_proba_xgb):.4f}\")\n",
    "\n",
    "print(\"\\nüèÜ XGBoost outperforms Logistic Regression on both F1 and AUC-PR metrics, making it the preferred model for this dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3456c8ec-8d4d-4d5f-97a0-2f81eb5c8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "D:\\10Academy1\\fraud_detection\\week-8\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['ip_int']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Results:\n",
      "[[26964   429]\n",
      " [ 1249  1581]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     27393\n",
      "           1       0.79      0.56      0.65      2830\n",
      "\n",
      "    accuracy                           0.94     30223\n",
      "   macro avg       0.87      0.77      0.81     30223\n",
      "weighted avg       0.94      0.94      0.94     30223\n",
      "\n",
      "F1 Score: 0.653305785123967\n",
      "Average Precision (AUC-PR): 0.5745924264311452\n",
      "Training XGBoost...\n",
      "XGBoost Results:\n",
      "[[24039  3354]\n",
      " [ 1740  1090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90     27393\n",
      "           1       0.25      0.39      0.30      2830\n",
      "\n",
      "    accuracy                           0.83     30223\n",
      "   macro avg       0.59      0.63      0.60     30223\n",
      "weighted avg       0.87      0.83      0.85     30223\n",
      "\n",
      "F1 Score: 0.2996975529282376\n",
      "Average Precision (AUC-PR): 0.330638243855421\n",
      "\n",
      "Model Comparison:\n",
      "Logistic Regression ‚Üí F1: 0.6533, AUC-PR: 0.5746\n",
      "XGBoost             ‚Üí F1: 0.2997, AUC-PR: 0.3306\n",
      "‚úÖ Models and preprocessing pipeline saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
    "import os  # Import os for directory handling\n",
    "\n",
    "# 1. Load the processed fraud data\n",
    "data_path = '../data/fraud_cleaned.csv'  # Adjust path as needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 2. Define target and features\n",
    "target = 'class'\n",
    "X = df.drop(columns=[target, 'user_id', 'signup_time', 'purchase_time'])  # Drop IDs and timestamps if not used\n",
    "y = df[target]\n",
    "\n",
    "# 3. Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 4. Identify categorical and numerical columns\n",
    "categorical_cols = ['device_id', 'source', 'browser', 'sex', 'country']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# 5. Preprocessing pipeline: impute, scale numeric, one-hot encode categorical\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Impute numerical features\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_cols),\n",
    "    ('cat', Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute categorical features\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# 6. Apply preprocessing to training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# 7. Handle class imbalance with SMOTE on preprocessed training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# 8. Logistic Regression pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_pipeline.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict and evaluate Logistic Regression\n",
    "y_pred_lr = lr_pipeline.predict(X_test_processed)\n",
    "y_pred_proba_lr = lr_pipeline.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_pred_proba_lr))\n",
    "\n",
    "# 9. Prepare data for XGBoost (using preprocessed and resampled data)\n",
    "dtrain = xgb.DMatrix(X_train_res, label=y_train_res)\n",
    "dtest = xgb.DMatrix(X_test_processed, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    'scale_pos_weight': (y_train_res == 0).sum() / (y_train_res == 1).sum(),\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "y_pred_proba_xgb = xgb_model.predict(dtest)\n",
    "y_pred_xgb = (y_pred_proba_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(\"XGBoost Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_xgb))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_pred_proba_xgb))\n",
    "\n",
    "# 10. Summary model comparison\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Logistic Regression ‚Üí F1: {f1_score(y_test, y_pred_lr):.4f}, AUC-PR: {average_precision_score(y_test, y_pred_proba_lr):.4f}\")\n",
    "print(f\"XGBoost             ‚Üí F1: {f1_score(y_test, y_pred_xgb):.4f}, AUC-PR: {average_precision_score(y_test, y_pred_proba_xgb):.4f}\")\n",
    "\n",
    "# 11. Cleanup\n",
    "gc.collect()\n",
    "\n",
    "# 12. Save models and preprocessor\n",
    "model_dir = \"D:/10Academy1/fraud_detection/models\"  # Change to a valid path\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the preprocessing pipeline\n",
    "joblib.dump(preprocessor, f\"{model_dir}/preprocessor.pkl\")\n",
    "\n",
    "# Save the Logistic Regression pipeline\n",
    "joblib.dump(lr_pipeline, f\"{model_dir}/logistic_regression_pipeline.pkl\")\n",
    "\n",
    "# Save the XGBoost model\n",
    "xgb_model.save_model(f\"{model_dir}/xgboost_model.json\")\n",
    "\n",
    "print(\"‚úÖ Models and preprocessing pipeline saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72751ff8-42f2-41e5-8335-3924385726dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " Class\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "üîπ Logistic Regression Results:\n",
      "[[69444  1635]\n",
      " [   14   109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71079\n",
      "           1       0.06      0.89      0.12       123\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.53      0.93      0.55     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n",
      "F1 Score: 0.11676486341724691\n",
      "Average Precision (AUC-PR): 0.7038566346457426\n",
      "\n",
      "üîπ XGBoost Results:\n",
      "[[70894   185]\n",
      " [   18   105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.36      0.85      0.51       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.68      0.93      0.75     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "F1 Score: 0.5084745762711864\n",
      "Average Precision (AUC-PR): 0.8040573114816045\n",
      "\n",
      "üìå Credit Card Dataset - Model Comparison:\n",
      "Logistic Regression ‚Üí F1: 0.1168, AUC-PR: 0.7039\n",
      "XGBoost             ‚Üí F1: 0.5085, AUC-PR: 0.8041\n",
      "\n",
      "üèÜ XGBoost outperforms Logistic Regression on both F1 and AUC-PR metrics, making it the preferred model for this dataset.\n"
     ]
    }
   ],
   "source": [
    "# --- CREDIT CARD FRAUD DETECTION ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, average_precision_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "# 2. Check class distribution\n",
    "print(\"Class distribution:\\n\", df['Class'].value_counts(normalize=True))\n",
    "\n",
    "# 3. Features and labels\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# 4. Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Normalize features (Time & Amount)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Logistic Regression\n",
    "print(\"\\nüîπ Logistic Regression Results:\")\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = logreg.predict(X_test_scaled)\n",
    "y_proba_lr = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_proba_lr))\n",
    "\n",
    "# 7. XGBoost\n",
    "print(\"\\nüîπ XGBoost Results:\")\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "y_proba_xgb = xgb_model.predict(dtest)\n",
    "y_pred_xgb = (y_proba_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_xgb))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_proba_xgb))\n",
    "\n",
    "# 8. Model Comparison\n",
    "print(\"\\nüìå Credit Card Dataset - Model Comparison:\")\n",
    "print(f\"Logistic Regression ‚Üí F1: {f1_score(y_test, y_pred_lr):.4f}, AUC-PR: {average_precision_score(y_test, y_proba_lr):.4f}\")\n",
    "print(f\"XGBoost             ‚Üí F1: {f1_score(y_test, y_pred_xgb):.4f}, AUC-PR: {average_precision_score(y_test, y_proba_xgb):.4f}\")\n",
    "\n",
    "# 11. Model comparison & justification\n",
    "\n",
    "# Extract metrics\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "aucpr_lr = average_precision_score(y_test, y_proba_lr)\n",
    "\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "aucpr_xgb = average_precision_score(y_test, y_proba_xgb)\n",
    "\n",
    "# Comparison and justification message\n",
    "if (f1_xgb > f1_lr) and (aucpr_xgb > aucpr_lr):\n",
    "    print(\"\\nüèÜ XGBoost outperforms Logistic Regression on both F1 and AUC-PR metrics, making it the preferred model for this dataset.\")\n",
    "elif (f1_lr > f1_xgb) and (aucpr_lr > aucpr_xgb):\n",
    "    print(\"\\nüèÜ Logistic Regression outperforms XGBoost on both F1 and AUC-PR metrics, making it the preferred model for this dataset.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Models have mixed results:\")\n",
    "    if f1_xgb > f1_lr:\n",
    "        print(\"- XGBoost has a better F1 score.\")\n",
    "    else:\n",
    "        print(\"- Logistic Regression has a better F1 score.\")\n",
    "    if aucpr_xgb > aucpr_lr:\n",
    "        print(\"- XGBoost has a better AUC-PR.\")\n",
    "    else:\n",
    "        print(\"- Logistic Regression has a better AUC-PR.\")\n",
    "    print(\"Choose based on your priority metric or consider further evaluation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2094ca38-3575-4980-8c0d-fa31b33bf6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Results:\n",
      "[[55397  1467]\n",
      " [    8    90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56864\n",
      "           1       0.06      0.92      0.11        98\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.53      0.95      0.55     56962\n",
      "weighted avg       1.00      0.97      0.99     56962\n",
      "\n",
      "F1 Score: 0.10876132930513595\n",
      "Average Precision (AUC-PR): 0.724469435669471\n",
      "\n",
      "Starting XGBoost hyperparameter tuning...\n",
      "\n",
      "Best XGBoost params: {'objective': 'binary:logistic', 'eval_metric': 'aucpr', 'scale_pos_weight': np.float64(1.0), 'seed': 42, 'max_depth': 6, 'eta': 0.1, 'subsample': 0.8, 'colsample_bytree': 1, 'verbosity': 0}\n",
      "Best XGBoost F1 at threshold 0.5: 0.5260\n",
      "Optimal threshold based on max F1: 0.9809\n",
      "\n",
      "XGBoost Results with tuned threshold:\n",
      "[[56858     6]\n",
      " [   20    78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.93      0.80      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "F1 Score: 0.8571428571428571\n",
      "Average Precision (AUC-PR): 0.8465667518482527\n",
      "\n",
      "Model Comparison:\n",
      "Logistic Regression ‚Üí F1: 0.1088, AUC-PR: 0.7245\n",
      "XGBoost (tuned)    ‚Üí F1: 0.8571, AUC-PR: 0.8466\n",
      "\n",
      "üèÜ Best Model Selected: XGBoost (tuned)\n",
      "‚úÖ Saved: XGBoost (tuned) to ../models/xgboost_credit_model_xgb.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, average_precision_score, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1. Load Credit Card Fraud Data\n",
    "data_path = '../data/creditcard.csv'  # adjust path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 2. Define target and features\n",
    "target = 'Class'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# 3. Split data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Numerical features to scale\n",
    "numerical_cols = X.columns.tolist()\n",
    "\n",
    "# 5. Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Apply SMOTE to balance classes on training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 7. Train Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_proba_lr))\n",
    "\n",
    "# 8. Train XGBoost with simple hyperparameter grid search\n",
    "dtrain = xgb.DMatrix(X_train_res, label=y_train_res)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'aucpr',\n",
    "    'scale_pos_weight': (y_train_res == 0).sum() / (y_train_res == 1).sum(),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6],\n",
    "    'eta': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(\"\\nStarting XGBoost hyperparameter tuning...\")\n",
    "for max_depth in param_grid['max_depth']:\n",
    "    for eta in param_grid['eta']:\n",
    "        for subsample in param_grid['subsample']:\n",
    "            for colsample_bytree in param_grid['colsample_bytree']:\n",
    "                params.update({\n",
    "                    'max_depth': max_depth,\n",
    "                    'eta': eta,\n",
    "                    'subsample': subsample,\n",
    "                    'colsample_bytree': colsample_bytree,\n",
    "                    'verbosity': 0\n",
    "                })\n",
    "                model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "                y_proba = model.predict(dtest)\n",
    "                y_pred = (y_proba >= 0.5).astype(int)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_params = params.copy()\n",
    "                    best_model = model\n",
    "\n",
    "print(f\"\\nBest XGBoost params: {best_params}\")\n",
    "print(f\"Best XGBoost F1 at threshold 0.5: {best_f1:.4f}\")\n",
    "\n",
    "# 9. Threshold tuning for XGBoost\n",
    "y_proba_best = best_model.predict(dtest)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba_best)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "\n",
    "print(f\"Optimal threshold based on max F1: {best_threshold:.4f}\")\n",
    "\n",
    "# Predict with tuned threshold\n",
    "y_pred_best = (y_proba_best >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\nXGBoost Results with tuned threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"Average Precision (AUC-PR):\", average_precision_score(y_test, y_proba_best))\n",
    "\n",
    "# 10. Summary comparison\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Logistic Regression ‚Üí F1: {f1_score(y_test, y_pred_lr):.4f}, AUC-PR: {average_precision_score(y_test, y_proba_lr):.4f}\")\n",
    "print(f\"XGBoost (tuned)    ‚Üí F1: {f1_score(y_test, y_pred_best):.4f}, AUC-PR: {average_precision_score(y_test, y_proba_best):.4f}\")\n",
    "\n",
    "\n",
    "# Extract metrics\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "aucpr_lr = average_precision_score(y_test, y_proba_lr)\n",
    "\n",
    "f1_xgb_tuned = f1_score(y_test, y_pred_best)\n",
    "aucpr_xgb_tuned = average_precision_score(y_test, y_proba_best)\n",
    "\n",
    "# Decide best model\n",
    "if (f1_xgb_tuned > f1_lr) and (aucpr_xgb_tuned > aucpr_lr):\n",
    "    best_model_name = \"XGBoost (tuned)\"\n",
    "    best_model_final = best_model\n",
    "elif (f1_lr > f1_xgb_tuned) and (aucpr_lr > aucpr_xgb_tuned):\n",
    "    best_model_name = \"Logistic Regression\"\n",
    "    best_model_final = lr\n",
    "else:\n",
    "    # Mixed results ‚Äî choose based on priority metric (e.g., F1)\n",
    "    if f1_xgb_tuned >= f1_lr:\n",
    "        best_model_name = \"XGBoost (tuned)\"\n",
    "        best_model_final = best_model\n",
    "    else:\n",
    "        best_model_name = \"Logistic Regression\"\n",
    "        best_model_final = lr\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Selected: {best_model_name}\")\n",
    "\n",
    "\n",
    "\n",
    "# 12. Save the best model and any required preprocessor\n",
    "model_save_path = '../models'  # adjust this path as needed\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "if best_model_name == \"Logistic Regression\":\n",
    "    model_filename = 'xgboost_credit_model_lr.pkl'\n",
    "    joblib.dump(best_model_final, os.path.join(model_save_path, model_filename))\n",
    "    joblib.dump(scaler, os.path.join(model_save_path, 'scaler_credit.pkl'))  # Save scaler too\n",
    "else:\n",
    "    model_filename = 'xgboost_credit_model_xgb.json'\n",
    "    best_model_final.save_model(os.path.join(model_save_path, model_filename))  # For XGBoost use .json\n",
    "    joblib.dump(scaler, os.path.join(model_save_path, 'scaler_credit.pkl'))  # Save scaler too\n",
    "\n",
    "print(f\"‚úÖ Saved: {best_model_name} to {model_save_path}/{model_filename}\")\n",
    "\n",
    "\n",
    "# 11. Cleanup\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70609ff-5589-4532-8026-1e17748a2e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (week-8)",
   "language": "python",
   "name": "week-8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
